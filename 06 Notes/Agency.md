This is the common conception of Agecy

> : _Agency _simply means “the quality of being capable of taking action”. You and the people around you seem to have agency; while rocks generally do not. Inanimate objects are sometimes granted agency in a kind of humorous quote marks (eg “the washer decided to break today”); Agents _(entities that have agency) have_ goals _or_ purposes_, and the actions they take are seen as being in pursuit of these goals. Agency thus implies some rudimentary_ rationality_, and a degree of _autonomy_.

But a thermostat and a silicon algorithms are capable of taking action. 

A better distinction for me is going from a simple controller to an agent 

We are very good at discovering agency in the world what does it actually mean when we discover agency and when we discover our own agency and start to amplify it um by making models of who we are and how we deal with the world and with others and so on the minimal definition of agent that I found is 

>  A controller for future States 

The thermostat doesn't have a goal by itself right it just has a Target value and a sensor that tells the deviation from the target value and when that exceeds a certain threshold the heating is turned on and if it goes below a certain threshold the heating is turned off again and thats it so the thermostat is not an agent it's a purely reactive system

whereas an agent is proactive which means that it's trying to not just minimize the current deviation from the target value but the integral over a time span previously the future deviation so it builds an expectation about how an action is going to change this trajectory of the universe and over that trajectory it tries to figure out some measure of how big the compound Target deviation is going to be and so as a result you get a branching universe and the branches in this universe some of these branches depend on actions that are available to you and that translate into decisions that you can make move you into more or less preferable States and suddenly you have a system with emergent beliefs desires and intentions but to make that happen, to move from a controller to agency, and agent has been a controller with an integrated setpoint generator and the ability to control future states that requires that you can make models that are counterfactual so because the future universe doesn't exist right now you need to create a counterfactual universe The Future model of the future Universe maybe even a model of the past universe that allows you to reason about possible for future universes and so on and to make these
counter factual causal models of the universe you need to have a turing machine so without a computer without something that is too incomplete that insulates you from the causal structure of your
substrate that allows you to build representations regardless of what the universe says right now around you right you need to have that machine and the simplest uh system in nature that has turing machine integrated is the cell so uh it's very difficult to find a system in nature that is an agent that is not made from cells as a result maybe there are systems in nature that are able to compute things and make models but uh I I'm not aware of any so the simplest one that I know that can do this reliably is the cells or arrangement of sets and that can possess agency which is interesting thing that explains this coincidence that living things are agents and vice versa that the agent that we discover are mostly living things or there are robots that have computers built into them or uh virtual robots that have that rely on

computation so the ability to make models of the future is the prerequisite for agency and to make arbitrary models

which means structures that embody uh causal uh simulations of some sort that


### For and Against Teleology 
C ompetency could be treated as the capacity of a system for adaptive

control yeah yeah yeah one uh issue that I have with the notion

of goals and goal directedness is that sometimes you only have a tendency in a system to go in a certain direction and

so it's it's directed but the goal is something that can be emergent sometimes

it's not sometimes there is an explicit representation in the system of a discrete event that is associated or a class of events this fulfilling a

certain condition that the system has committed itself to and if you don't have that you don't have a proper goal but in real systems it's difficult to

say I mean when do we pursue goals right sometimes we just are vaguely hungry are

moving towards the kitchen because we hope that something will opportunistically emerge that will deal

with this vague tendency in our Behavior we could also say we have the goal of finding food but uh that is a

rationalization that is maybe stretching sick sometimes yeah so uh sometimes a