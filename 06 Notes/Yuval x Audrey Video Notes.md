do you worry about the situation which Yuval describes where
technology can know ourselves better than we know ourselves and before we know ourselves?

### Audrey

Audrey: A lot of my work is to ensure that social sectors, in RadicalxChange terms, a data coalition or data cooperative owns the means of production – in this case, the production of data. That is to say if people produce data in a way that is passive, that enables a surveillance state or surveillance capitalism, that will lead to the scenario where Yuval has very

But if the social sector, that is to say, if ordinary citizens can understand that they’re

collecting, for example, in Taiwan, the leading contact tracing technology, the winner of

our coronavirus Hackathon, Logboard, they collect the whereabouts, their temperatures,

their symptoms and so on, but it never transmits anywhere. It keeps it strictly within their

phone and not anywhere else.

When the contact tracers, the medical officers come to investigate, it generates a one-time

link that has exactly the kind of information that contact tracing needs without divulging

any private details about their friends and families, as would often be revealed by a

traditional contact tracing interview.

### Yuval

The biggest danger really is the rise of a new kind of totalitarianism that we have never

seen before in history simply because it’s now technically feasible to follow everybody

all the time.

Even in the darkest moments of the 20th century – in Stalin’s Russia or in Mao’s China

– it was simply technically impossible to follow everybody all the time and to know

them better than you know yourself.

If you need the police or government agent, KGB agent to follow everybody 24 hours a day,

you don’t have enough agents. Even if you have all the agents, they just produce paper

reports about what you do. Somebody needs to read the reports and analyze them

But an even deeper question is, let’s say we succeed in preventing the rise of digital

dictatorship, when some government follows us all the time and knows everything about

us, what happens if the data is really collected in a responsible and secure way? It serves

us and not the government or some big corporation.

Still, the deep, philosophical question is even in this situation, authority is likely

to shift away from humans to algorithms in the most important decisions of our lives,

like where to study or where to work or whom to marry.

It’s not that I have this online government that forces me to do something. It’s just

that I know the algorithm knows me far better than I know myself and can make recommendations

for me, and I increasingly just rely on what the algorithm tells me.

It improves all the time. The algorithm doesn’t need to be perfect. It just needs to be better

on average than the mean in making these decisions and gradually the authority will shift.

Philosophically, I think this is the really big question of our time. Even if we prevent

the dystopian scenario of digital dictatorships, how do we deal with democratic algorithms

that serve us, but still know us better than we know ourselves?

### Audrey 

So, it also regulates what is transparent. For example, code can make the state transparent

to the citizen, as Taiwan does, or, it can make citizens transparent to the state, as

the PRC does and things like that.

Every time that we deploy code as part of our society, it establishes a normativity.

That is, it tells us what’s legal, what’s even thinkable by these lines, just like physics.

You cannot even think of, “Oh, I’m going to violate a physics law today,” because

that’s just not how the world works.

That basically has a very different position than our current, text-based, normativity.

When you can do civil disobedience, you willfully occupy the Parliament, as we did in 2014.

Then you argue it’s legal and you convince the judges.

So, the impact, as Yuval said, is that whenever we deploy code, we must have the same kind

of access to justice, to the same kind of access to the open futures, to the different

interpretations that’s either agreed to by the social norm, which would be a positive

impact, or it will be set a few people and basically restrict everybody else’s imagination,

which would have a negative social impact, even if it is not by one or two actors.

Even if it’s by tens of thousands of programmers, that still is a kind of restriction, and to

me, also a negative social impact.

### Yuval 

> Civic Hackers 


So I think that is the kind of norm that I’m saying that the code-makers if it doesn’t

allow for future interpretations, if the maker of the check boxes doesn’t allow for an

other or non-binary choice, which by the way Taiwan provides for people arriving to our

airports when you’re doing the health check form, if you don’t design that in then of

course 

> you would still rely on people who are civic hackers, meaning that they imagine different civic futures to patch it in. However, Taiwan is the only jurisdiction in Asia that has the complete freedom of assembly, of speech, and so on, so civic hackers will not be punished unduly. In every other place in Asia, just let like same-sex marriage is not possible, 
> 
> this kind of civic hacking can often get people in trouble. To me, that reflects how much a society is willing to look at its algorithmic code as flexible as its legal code with a due process of change. - Audrey Tang 

### Yuval 

This issue of, again, the difference between natural law that shapes our life and the rules

that we invent, it’s one of the main themes of history. Of course, every culture, every

religion claims their rules, their laws are the laws of nature and those who break the

law are doing something unnatural.

This is obviously wrong. As you said, if a law is really natural, you simply cannot break

it. If some religion comes and says, “For two men to love one another or for two women

to get married with one another, this is unnatural,” this is, by definition, wrong.

A real natural law, like you can’t move faster than the speed of light, you simply

can’t break it. It’s not up to you. 

`Is it breakable`

Obviously, biology and physics enable two women to love

each other or to have sex with one another. It’s only human code which says, “No,

no, no, no, no. This is wrong. We don’t want to allow it.”

The good thing, in a way, about computer code is that in many cases, even though of course

computer code has inside it a lot of biases, either programmed intentionally by human engineers

or programmed unintentionally, still the good thing about computer code is that in essence

it can be corrected much more easily.

If a human being has a bias against, say, gay people or against black people, you can

explain to that. You can discover, “Oh, this person or this system, the codes have

a bias.” You can explain to people. People can even agree. That will not be enough to

change the bias because the bias comes from some place far deeper than our conscious intelligence.

It comes from our subconscious.

> Now in computer code, you can say computers don’t have a subconscious. If you find where in the code the bias is encoded and you change that, in a way it’s much easier to make a computer code gay-friendly or LGBT-friendly than to make a human being change their biases. - Yuval Noah Harrari

### Audrey 

The point here is that if people feel that they have a stake in the norm and just with

a simple phone call and regardless of age…That boy probably isn’t of legal age, probably

isn’t 18 years old.

Just through this simple phone call and convincing in a very natural manner and appealing to

the CECC’s idea of mask for all, if a few boys doesn’t wear mask because it’s pink,

then it actually is a public health threat to everybody else as well. Because of that,

`Fast Iteration cycle `

This fast iteration cycle, this agile response, that makes the social sector more strong and

more robust because everybody, instead of waiting for the command from the command center,

they can actually just participate in the code making.

---

seems to be a participatory

framework combined with fast iterations. Is that how you would characterize the solution?

### Audrey 

Yeah, definitely. It also must be fair and also fun, which I will get to later. The fast

part, yes, it’s essential.

If the government only responds with those what we call patches, fixes to the system,

if we respond only every year or even every four years in case of votes and elections,

which is like three bits uploaded every four years, then there’s just not sufficient

signal to correct a previously biased or wrong code.

If everybody can very freely fork, that is to say develop alternate visions, and also

merge within a 24-hour cycle, then something magical happens. It enable the few civic technologists

to become like civil engineers.

Their work will be then used by over half of the population, which makes these code

makers the same kind of role as the highway makers, the road makers, and so on but with

the additional benefit of everybody being able to imagine different futures.

If it gets rough consensus, that is to say if a lot of people can live with it, then

it just turns into the overall new reality for the society in a very rapid fashion, like

from pink being sissy to pink being very hip and cool. It’s literally just 24 hours.

---

### Yuval 

The main issue for me, again from historical perspective, is that democracy gives authority

to the desires and feelings of people. This is the ultimate authority in a democracy.

I completely agree that letting people voice their desires, their feelings just once in

four years is certainly not enough. It’s not efficient.

---

 What is the proper relationship with

this kind of entity?

One more thing. We had this kind of entity throughout history in a way – a mother or

father or teacher. My mother is somebody, who when I was 14, maybe she didn’t know

I was gay, but she knew a lot of things about me I didn’t realize.

But my mother had my best interests in mind when thinking how to use this information

about me, and we have thousands of years of experience in building the kind of beneficial

parent-child relationship.

Now we are suddenly creating a completely new kind of entity who actually knows about

me far more even than my mother, and we have no cultural or historical traditions about

what kind of relationship I have with my AI mentor that has all this information about

me.

---

What kinds of relationships will emerge out of this new technology. 

### Audrey 

`Manipulative Ads and accountability`

Yes, to this point – actually there were two points. One is the lack of accountability,

there was the Coca-Cola example, and one was value alignment, which is all watched over

by machines of loving grace. The first point is easier to address.

Taiwan, in our previous presidential election, managed to establish a norm through a completely

independent branch of the government called the Control Yuan, or the Control Branch, that

makes campaign donations and campaign expenses radically transparent, meaning the raw data

is published for independent journalists to analyze.

They’ve been doing this because, we, the civic hacktivists, have been petitioning this,

even doing acts of civil disobedience for that.

When we really started doing that, back in the mayoral election in 2018, we discovered

that there’s a large chunk missing. The social media advertisements, these were not

reported as campaign donations, neither as expenses. Many of them came from outside Taiwan

and we don’t know. It really is an unaccountable, black-box.

We read of course the reports about how some foreign powers interfered with some other

countries’ elections using high-prepositioned targeting technology, exactly the kind that

Yuval described.

It predicts in a micro-prediction way what people’s hidden fears and hopes are. They

cater to those fears and hopes and just target this very tiny slice of people, trying to

persuade them to not go to vote, or to avoid a certain kind of candidate, or do some kind

of emotional manipulation.

We tell all the multinationals, look at our Control Yuan. This radical transparency is

the Taiwanese norm, and you have two choices. You can either publish your real-time advertisement

library just as our Control Yuan does in radical transparency, so people engaging in such stark

manipulations will be discovered and shamed, or you can just simply not run political and

social advertisements during our election session. Your choice.

We did not pass a law for that. We basically just let them know there will be social sanctions

if you violate the Control Yuan norm, our election norm. Facebook decided to radically

open their ads library, while Google and Twitter and so on just simply refuse to run political

advertisements during our election.

So that is a very neat example to the accountability issue, which is more to me a minor issue.

> Instead of user experience, we need to think about human experience.

You only care about the time that you spent addicted with that technology when you use

the term user. It’s a zero-sum gain of attention and time span.

But if you think of the total human experience, then these different interpretations may add

to one another and eventually liberate one self from one, singular vision of one self.


### Yuval 

But if you start with a baby, or a young child, and more and more decisions about the life

of the child are taken by an AI mentor, again, not an evil mentor that actually serves some

corporation, a mentor which is supposedly really serving the interests of that child

– it learns on the way, it changes – you trust the algorithm.

You don’t really know where are these decisions coming from. A human can’t go over all the

data and understand it, and these decisions shape the values of the child, as she or he

is growing up.

### direct

The idea of data dignity is that you separate control and use of the data. So when you separate

those two, you ultimately are breaking the monopoly and monopsony on the data that big

tech and big governments have.

If you do that, and you separate control and use, then you can imagine that there’s going

to be lots of different data cooperatives or collectives which can accept or reject

algorithms. You can imagine a plurality of algorithms on top of a plurality of these

collectives which we choose from.

### Audrey 

`City as School`

In any case, what I’m trying to get to is that in Taiwan, our new curriculum, starting

last year, advised the children to set their own projects to solve structural problems

by problem-based learning.

And teachers…it could be institutional, it could be in the community college, it could

be in the local, elderly learning groups and so on, indigenous language circles and so

These are the different circles that this child, when they care, for example, about

climate change, they can reach out to the various circles interested in that thing instead

of relying on the textbook teaching them the truths and thoughts about climate science,

which doesn’t make sense unless you have a compelling motivation to understand and 
solve this problem. 

The idea of self-motivational learning is at the core of our new curriculum, and this is after decades of alternative, experimental, home-schooling, all sorts of different education experiments in Taiwan, which are legal, all of them. Up to 10 percent of Taiwanese young people can choose their own curriculum, free of the official one, for the past decade or so. After we learned from what worked and what didn’t, we decided that this kind of autonomous joining circles that tackle the same problem is the best way to free from individual-to-individual competition, which tends to dominate East Asian education thought. Once you get trapped into that linear growth then of course you will have the first place, second place, third place as if on the same runners’ track. But if you’re attracted to a systemic problem that you seek to solve, then you basically choose your own course and you win at the starting point.


### Yuval 

In the traditional way of school, you go to music class. So music class is every Tuesday,

at 11 o’clock. That’s it. This is when you are supposed to be exposed to new kinds

of music.

But maybe on Tuesday, at 11 o’clock, I am very tired, or I am concerned about something.

This is the worst moment to try and introduce me to jazz, or to Indonesian gamelan music.

The AI will know that actually at seven o’clock in the evening, on that particular day, I

am much more open, so it will try then.

In this way, hacking human beings does not necessarily mean imprisoning them in their

own previous preferences and biases, it can lead to unprecedented variety and exploration.

### Audrey 

I don’t know about you. [laughs] I find touch screen very addictive and I don’t

really like being addicted to the surface.

Being a feature phone, I deliberatively restrict my input bandwidth to this device so that

this device probably will never, if I manage my attention well, have the sufficient bits

about my preferences to make the kind of exploratory judgments or interpretations that Yuval just

described It, which is, in technical terms, a blended volition of my different moments

or across my communities and so on.

When it try to wildly guess my preferences, extrapolating my volition, because my input

bits to it is so low, it invariably gets it very wrong, even hilariously wrong and so

I will not pay much attention to it.

This is like wearing a medical mask. This protects…I’m not talking about the biological

germs and viruses, but I’m using it as an analogy. I use, for example, the Facebook

Feed Eradicator which is like a mental medical mask. If you install this plug-in, it removes

the Facebook feed from the Facebook app, from the website.

Everything that are autonomous, that is to say, if you intentionally do it, that’s

still possible. You can still do search, view live streams or whatever, but all the unpredictable

part, those that pushes your emotional or dopamine or whatever buttons, these disappears

and replace it with a Zen saying or an Adler saying or whatever saying.

What I’m trying to say is that before the society developed a norm of counter spam,

of people flagging things as spam, there’s been things like spam assassin, for lack of

a better name, things that you can install by yourself like a personal protective equipment.

Finally, people figure out the norm around spam. Nowadays, we don’t worry about spam

mail that much because we understand that our attention is too precious to give to the

spammers. It is either a vicious cycle of you giving it more attention and the scammers

have more bits to work with, or if you deny them the initial contact and then you protect

you and your own community from the ripple effect.